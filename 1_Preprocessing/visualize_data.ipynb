{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a857ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import polars as pl\n",
    "# Auto-reload modules when they change (helpful during development)\n",
    "import importlib\n",
    "import datapreprocessing\n",
    "importlib.reload(datapreprocessing)\n",
    "from datapreprocessing import DataPreprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5400f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists in '/Users/mpecaut/Fin_Big_Data/data_volbars'\n",
      "Lezzzggooooo, found 84 processed files\n",
      "Loading 84 processed assets...\n",
      "  Loaded 10/84 assets...\n",
      "  Loaded 20/84 assets...\n",
      "  Loaded 30/84 assets...\n",
      "  Loaded 40/84 assets...\n",
      "  Loaded 50/84 assets...\n",
      "  Loaded 60/84 assets...\n",
      "  Loaded 70/84 assets...\n",
      "  Loaded 80/84 assets...\n",
      "  Loaded 84/84 assets...\n",
      "\n",
      "✓ Successfully loaded 84 assets\n",
      "Tickers: ['ALL.N', 'DOW.N', 'NKE.N', 'F.N', 'MON.N', 'BA.N', 'KO.N', 'JPM.N', 'C.N', 'CL.N']...\n",
      "\n",
      "============================================================\n",
      "INDUSTRY MAPPING RESULTS:\n",
      "============================================================\n",
      "communication_services :   4 stocks\n",
      "consumer_cyclical    :   6 stocks\n",
      "consumer_defensive   :  11 stocks\n",
      "energy               :  11 stocks\n",
      "financials           :  14 stocks\n",
      "healthcare           :   9 stocks\n",
      "industrials          :  14 stocks\n",
      "materials            :   5 stocks\n",
      "technology           :   6 stocks\n",
      "utilities            :   4 stocks\n",
      "\n",
      "Total stocks mapped: 84\n",
      "Unknown stocks: 0\n",
      "\n",
      "============================================================\n",
      "DATA CLEANING RESULTS:\n",
      "============================================================\n",
      "Original data: 84 tickers (with suffix)\n",
      "Cleaned data_clean: 84 tickers (without suffix)\n",
      "\n",
      "All asset tickers have been correctly transformed\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "raw_data_path = '/Users/mpecaut/Desktop/data_parquet'\n",
    "clean_data_path = '/Users/mpecaut/Fin_Big_Data/data_clean'\n",
    "\n",
    "# Date filter (optional - if None, will use first 3 months from each asset)\n",
    "start_date = '2008-09-01'  # Or None for auto\n",
    "end_date = '2008-12-31'    # Or None for auto\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessing = DataPreprocessing(folder_path=raw_data_path, \n",
    "                                  output_path=clean_data_path,\n",
    "                                  start_date=start_date,\n",
    "                                  end_date=end_date)\n",
    "\n",
    "# Process all assets (this will create {ticker}_clean.parquet files)\n",
    "# With date filtering, this should be MUCH faster!\n",
    "preprocessing.process_all_assets()\n",
    "\n",
    "# Load cleaned data\n",
    "data_dict = preprocessing.load_cleaned_data()\n",
    "\n",
    "print(f\"\\nLoaded {len(data_dict)} cleaned assets\")\n",
    "print(f\"Example ticker: {list(data_dict.keys())[0]}\")\n",
    "print(f\"\\nExample data:\")\n",
    "print(data_dict[list(data_dict.keys())[0]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a6c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pl.read_parquet('panel_data_1min.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a47cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_731_247, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>ticker</th><th>ask-price</th><th>ask-volume</th><th>bid-price</th><th>bid-volume</th><th>spread</th><th>mid-price</th><th>volume_imbalance</th><th>industry</th></tr><tr><td>datetime[μs]</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>2008-09-02 13:30:00</td><td>&quot;ABT&quot;</td><td>58.537504</td><td>605.0</td><td>58.309401</td><td>484.0</td><td>0.228103</td><td>58.423452</td><td>-0.111111</td><td>&quot;healthcare&quot;</td></tr><tr><td>2008-09-02 13:30:00</td><td>&quot;ALL&quot;</td><td>45.75773</td><td>163.0</td><td>45.637612</td><td>67.0</td><td>0.120118</td><td>45.697671</td><td>-0.417391</td><td>&quot;financials&quot;</td></tr><tr><td>2008-09-02 13:30:00</td><td>&quot;BAC&quot;</td><td>33.0075</td><td>13393.0</td><td>32.955497</td><td>8656.0</td><td>0.052003</td><td>32.981498</td><td>-0.21484</td><td>&quot;financials&quot;</td></tr><tr><td>2008-09-02 13:30:00</td><td>&quot;BAX&quot;</td><td>68.484787</td><td>328.0</td><td>68.272418</td><td>153.0</td><td>0.212368</td><td>68.378602</td><td>-0.363825</td><td>&quot;healthcare&quot;</td></tr><tr><td>2008-09-02 13:30:00</td><td>&quot;BK&quot;</td><td>35.3655</td><td>280.0</td><td>35.302484</td><td>153.0</td><td>0.063016</td><td>35.333992</td><td>-0.293303</td><td>&quot;financials&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2008-12-30 21:55:00</td><td>&quot;T&quot;</td><td>28.24</td><td>1065.0</td><td>28.19</td><td>1.0</td><td>0.05</td><td>28.215</td><td>-0.998124</td><td>&quot;communication_services&quot;</td></tr><tr><td>2008-12-30 21:55:00</td><td>&quot;WAG&quot;</td><td>23.96</td><td>53.0</td><td>23.94</td><td>106.0</td><td>0.02</td><td>23.95</td><td>0.333333</td><td>&quot;consumer_defensive&quot;</td></tr><tr><td>2008-12-30 21:55:00</td><td>&quot;WFC&quot;</td><td>28.82</td><td>1.0</td><td>28.7</td><td>59.0</td><td>0.12</td><td>28.76</td><td>0.966667</td><td>&quot;financials&quot;</td></tr><tr><td>2008-12-30 21:55:00</td><td>&quot;WMB&quot;</td><td>14.33</td><td>415.0</td><td>14.31</td><td>606.0</td><td>0.02</td><td>14.32</td><td>0.187071</td><td>&quot;energy&quot;</td></tr><tr><td>2008-12-30 21:55:00</td><td>&quot;XRX&quot;</td><td>7.73</td><td>63.0</td><td>7.71</td><td>953.0</td><td>0.02</td><td>7.72</td><td>0.875984</td><td>&quot;technology&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_731_247, 10)\n",
       "┌────────────┬────────┬───────────┬────────────┬───┬──────────┬───────────┬────────────┬───────────┐\n",
       "│ timestamp  ┆ ticker ┆ ask-price ┆ ask-volume ┆ … ┆ spread   ┆ mid-price ┆ volume_imb ┆ industry  │\n",
       "│ ---        ┆ ---    ┆ ---       ┆ ---        ┆   ┆ ---      ┆ ---       ┆ alance     ┆ ---       │\n",
       "│ datetime[μ ┆ str    ┆ f64       ┆ f64        ┆   ┆ f64      ┆ f64       ┆ ---        ┆ str       │\n",
       "│ s]         ┆        ┆           ┆            ┆   ┆          ┆           ┆ f64        ┆           │\n",
       "╞════════════╪════════╪═══════════╪════════════╪═══╪══════════╪═══════════╪════════════╪═══════════╡\n",
       "│ 2008-09-02 ┆ ABT    ┆ 58.537504 ┆ 605.0      ┆ … ┆ 0.228103 ┆ 58.423452 ┆ -0.111111  ┆ healthcar │\n",
       "│ 13:30:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ e         │\n",
       "│ 2008-09-02 ┆ ALL    ┆ 45.75773  ┆ 163.0      ┆ … ┆ 0.120118 ┆ 45.697671 ┆ -0.417391  ┆ financial │\n",
       "│ 13:30:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ s         │\n",
       "│ 2008-09-02 ┆ BAC    ┆ 33.0075   ┆ 13393.0    ┆ … ┆ 0.052003 ┆ 32.981498 ┆ -0.21484   ┆ financial │\n",
       "│ 13:30:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ s         │\n",
       "│ 2008-09-02 ┆ BAX    ┆ 68.484787 ┆ 328.0      ┆ … ┆ 0.212368 ┆ 68.378602 ┆ -0.363825  ┆ healthcar │\n",
       "│ 13:30:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ e         │\n",
       "│ 2008-09-02 ┆ BK     ┆ 35.3655   ┆ 280.0      ┆ … ┆ 0.063016 ┆ 35.333992 ┆ -0.293303  ┆ financial │\n",
       "│ 13:30:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ s         │\n",
       "│ …          ┆ …      ┆ …         ┆ …          ┆ … ┆ …        ┆ …         ┆ …          ┆ …         │\n",
       "│ 2008-12-30 ┆ T      ┆ 28.24     ┆ 1065.0     ┆ … ┆ 0.05     ┆ 28.215    ┆ -0.998124  ┆ communica │\n",
       "│ 21:55:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ tion_serv │\n",
       "│            ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ ices      │\n",
       "│ 2008-12-30 ┆ WAG    ┆ 23.96     ┆ 53.0       ┆ … ┆ 0.02     ┆ 23.95     ┆ 0.333333   ┆ consumer_ │\n",
       "│ 21:55:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ defensive │\n",
       "│ 2008-12-30 ┆ WFC    ┆ 28.82     ┆ 1.0        ┆ … ┆ 0.12     ┆ 28.76     ┆ 0.966667   ┆ financial │\n",
       "│ 21:55:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ s         │\n",
       "│ 2008-12-30 ┆ WMB    ┆ 14.33     ┆ 415.0      ┆ … ┆ 0.02     ┆ 14.32     ┆ 0.187071   ┆ energy    │\n",
       "│ 21:55:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆           │\n",
       "│ 2008-12-30 ┆ XRX    ┆ 7.73      ┆ 63.0       ┆ … ┆ 0.02     ┆ 7.72      ┆ 0.875984   ┆ technolog │\n",
       "│ 21:55:00   ┆        ┆           ┆            ┆   ┆          ┆           ┆            ┆ y         │\n",
       "└────────────┴────────┴───────────┴────────────┴───┴──────────┴───────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d334941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily trading hours:\n",
      "shape: (84, 5)\n",
      "┌────────────┬────────────┬──────────┬──────────────┬────────────────┐\n",
      "│ date       ┆ start_time ┆ end_time ┆ duration     ┆ n_observations │\n",
      "│ ---        ┆ ---        ┆ ---      ┆ ---          ┆ ---            │\n",
      "│ date       ┆ time       ┆ time     ┆ duration[μs] ┆ u32            │\n",
      "╞════════════╪════════════╪══════════╪══════════════╪════════════════╡\n",
      "│ 2008-09-02 ┆ 13:30:00   ┆ 20:49:00 ┆ 7h 19m       ┆ 32847          │\n",
      "│ 2008-09-03 ┆ 13:30:00   ┆ 20:49:00 ┆ 7h 19m       ┆ 32901          │\n",
      "│ 2008-09-04 ┆ 13:30:00   ┆ 20:49:00 ┆ 7h 19m       ┆ 32915          │\n",
      "│ 2008-09-05 ┆ 13:30:00   ┆ 21:03:00 ┆ 7h 33m       ┆ 32912          │\n",
      "│ 2008-09-08 ┆ 13:30:00   ┆ 20:49:00 ┆ 7h 19m       ┆ 32911          │\n",
      "│ …          ┆ …          ┆ …        ┆ …            ┆ …              │\n",
      "│ 2008-12-23 ┆ 14:30:00   ┆ 21:49:00 ┆ 7h 19m       ┆ 33023          │\n",
      "│ 2008-12-24 ┆ 14:30:00   ┆ 19:39:00 ┆ 5h 9m        ┆ 17768          │\n",
      "│ 2008-12-26 ┆ 14:30:00   ┆ 21:51:00 ┆ 7h 21m       ┆ 32904          │\n",
      "│ 2008-12-29 ┆ 14:30:00   ┆ 21:49:00 ┆ 7h 19m       ┆ 32960          │\n",
      "│ 2008-12-30 ┆ 14:30:00   ┆ 21:55:00 ┆ 7h 25m       ┆ 32997          │\n",
      "└────────────┴────────────┴──────────┴──────────────┴────────────────┘\n",
      "\n",
      "Most common start time: 13:30:00\n",
      "Most common end time: 20:49:00\n",
      "Average observations per day: 32515\n"
     ]
    }
   ],
   "source": [
    "# Analyze daily time availability\n",
    "\n",
    "# Extract date and time components\n",
    "daily_times = all.select([\n",
    "    pl.col('timestamp').dt.date().alias('date'),\n",
    "    pl.col('timestamp').dt.time().alias('time'),\n",
    "    'timestamp'\n",
    "])\n",
    "\n",
    "# Get min and max time for each day\n",
    "daily_range = all.group_by(pl.col('timestamp').dt.date().alias('date')).agg([\n",
    "    pl.col('timestamp').min().alias('first_timestamp'),\n",
    "    pl.col('timestamp').max().alias('last_timestamp'),\n",
    "    pl.col('timestamp').count().alias('n_observations')\n",
    "]).sort('date')\n",
    "\n",
    "# Extract just the time portions for easier reading\n",
    "daily_summary = daily_range.with_columns([\n",
    "    pl.col('first_timestamp').dt.time().alias('start_time'),\n",
    "    pl.col('last_timestamp').dt.time().alias('end_time'),\n",
    "    (pl.col('last_timestamp') - pl.col('first_timestamp')).alias('duration')\n",
    "])\n",
    "\n",
    "print(\"Daily trading hours:\")\n",
    "print(daily_summary.select(['date', 'start_time', 'end_time', 'duration', 'n_observations']))\n",
    "\n",
    "# Show summary statistics\n",
    "print(f\"\\nMost common start time: {daily_summary['start_time'].mode()[0]}\")\n",
    "print(f\"Most common end time: {daily_summary['end_time'].mode()[0]}\")\n",
    "print(f\"Average observations per day: {daily_summary['n_observations'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350f290",
   "metadata": {},
   "source": [
    "### Covariance matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b817bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.load('covariance_denoised.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474769e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (84,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ticker</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;WY&quot;</td></tr><tr><td>&quot;MON&quot;</td></tr><tr><td>&quot;WMB&quot;</td></tr><tr><td>&quot;GS&quot;</td></tr><tr><td>&quot;NSC&quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;MRK&quot;</td></tr><tr><td>&quot;MS&quot;</td></tr><tr><td>&quot;F&quot;</td></tr><tr><td>&quot;JNJ&quot;</td></tr><tr><td>&quot;TWX&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (84,)\n",
       "Series: 'ticker' [str]\n",
       "[\n",
       "\t\"WY\"\n",
       "\t\"MON\"\n",
       "\t\"WMB\"\n",
       "\t\"GS\"\n",
       "\t\"NSC\"\n",
       "\t…\n",
       "\t\"MRK\"\n",
       "\t\"MS\"\n",
       "\t\"F\"\n",
       "\t\"JNJ\"\n",
       "\t\"TWX\"\n",
       "]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670ffd28",
   "metadata": {},
   "source": [
    "## Example Factor Ideas:\n",
    "\n",
    "### 1. **Cross-Sectional Factors** (relative to industry)\n",
    "- Relative spread: How wide is this stock's spread vs industry average?\n",
    "- Relative volume imbalance: Is buying pressure stronger than peers?\n",
    "- Relative volatility: Is this stock more volatile than industry?\n",
    "\n",
    "### 2. **Industry Momentum Factors**\n",
    "- Industry return: Average return across all stocks in industry\n",
    "- Industry spread widening: Is the whole industry becoming less liquid?\n",
    "\n",
    "### 3. **Lead-Lag Relationships**\n",
    "- Does one stock's price movement predict others in the industry?\n",
    "- Order flow spillover effects\n",
    "\n",
    "**Next Step:** Do you have an industry classification for your tickers, or do you need to create one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Align data to common time grid for cross-sectional analysis\n",
    "def align_to_time_grid(data_dict, freq='5min'):\n",
    "    \"\"\"\n",
    "    Resample all volatility bars to a common time grid\n",
    "    This allows cross-sectional comparison at each time point\n",
    "    \n",
    "    Args:\n",
    "        data_dict: Dictionary of {ticker: DataFrame}\n",
    "        freq: Time frequency for alignment ('5min', '15min', '1H', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of {ticker: aligned DataFrame}\n",
    "    \"\"\"\n",
    "    aligned_data = {}\n",
    "    \n",
    "    for ticker, df in data_dict.items():\n",
    "        # Calculate mid-price and spread\n",
    "        df['mid_price'] = (df['bid-price_mean'] + df['ask-price_mean']) / 2\n",
    "        df['spread'] = df['ask-price_mean'] - df['bid-price_mean']\n",
    "        df['volume_imbalance'] = (df['bid-volume_sum'] - df['ask-volume_sum']) / (df['bid-volume_sum'] + df['ask-volume_sum'])\n",
    "        \n",
    "        # Resample to common time grid\n",
    "        aligned = df.resample(freq).agg({\n",
    "            'mid_price': 'last',\n",
    "            'bid-price_mean': 'last',\n",
    "            'ask-price_mean': 'last',\n",
    "            'spread': 'mean',\n",
    "            'bid-volume_sum': 'sum',\n",
    "            'ask-volume_sum': 'sum',\n",
    "            'volume_imbalance': 'mean',\n",
    "            'bar_duration': 'mean'  # Average volatility regime\n",
    "        }).dropna()\n",
    "        \n",
    "        aligned_data[ticker] = aligned\n",
    "    \n",
    "    return aligned_data\n",
    "\n",
    "# Example: Align to 5-minute grid\n",
    "aligned_data = align_to_time_grid(data_dict, freq='5min')\n",
    "print(f\"Aligned {len(aligned_data)} assets to common time grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industries:\n",
      "  financials: 14 stocks\n",
      "  materials: 5 stocks\n",
      "  consumer_cyclical: 6 stocks\n",
      "  industrials: 14 stocks\n",
      "  consumer_defensive: 11 stocks\n",
      "  communication_services: 4 stocks\n",
      "  healthcare: 9 stocks\n",
      "  technology: 6 stocks\n",
      "  energy: 11 stocks\n",
      "  utilities: 4 stocks\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "industries = defaultdict(list)\n",
    "for ticker, industry in industry_mapping.items():\n",
    "    industries[industry].append(ticker)\n",
    "\n",
    "print(\"Industries:\")\n",
    "for industry, tickers in industries.items():\n",
    "    print(f\"  {industry}: {len(tickers)} stocks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finbigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
